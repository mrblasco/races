```{r}
read_chunk("R/results.R")
read_chunk("R/results_sorting.R")
```

# Results
At the end of the eight day submission period of the contest, we collected individual data like the number, timing, and score of each code submission made by competitors. As competitors behaviors are generally correlated within each room, we then aggregated these individual data into room responses to examine differences between competition styles at the room level.[^dependence]

[^dependence]: While such a dependence does not generally affect estimatation of mean differences, it might bias inference accuracy. As actions across rooms can be treated as independent, the inferential problem is thus less severe when the analysis is at the room level.

## Entry
Our analysis of the effects of different competition styles begins by looking at competitors' entry. The entry variable is the fraction of competitors in a room who made at least one submission during the eight day submission period of the contest. Our theoretical model predicts that, all else being equal, competitors' entry will be higher in a tournament than in a race competition, because of the lack of minimum performance requirements. For the same reason, it also predicts higher entry rates in regular tournaments compared to tournaments with reserve. Consistent with these predictions, Figure \ref{room entrants} shows a higher median percentage of entrants in tournaments compared to both races and tournaments with reserve. It also shows that the difference in entry between tournaments and races, though it is consistently positive across room sizes, seemed more marked in small rooms compared to large rooms, suggesting sobering effects associated with size.

```{r entryPlot, fig.width=9, fig.height=4, include=FALSE}
```

\begin{figure}
\caption{Percentage of room entrants by competition and room size}
\label{room entrants}
\includegraphics{Figures/entryPlot-1.pdf}
\end{figure}

On average, `r entry.diff['tournament']` competitors (`r entry.pcnt['tournament']` percent) assigned to tournaments were submitting solutions compared to `r entry.diff['race']` competitors  (`r entry.pcnt['race']` percent) assigned to races and `r entry.diff['reserve']`  (`r entry.pcnt['reserve']` percent) assigned to tournaments with reserve. To test if the observed positive difference in entry between tournaments and races was statistically greater than zero, we used a multiple linear regression model. We regressed the fraction of entrants in each room against treatment dummies and room size dummies. To control for random differences in competitors' baseline characteristics across rooms, we added controls for differences in room abilities and demographics.[^controls]

[^controls]: We consider two sets of room controls: a "partial set" and a "full set." The partial set includes  control variables with a relatively higher chance of being different across treatment groups. Those are variables with a relatively high (i.e., equal or larger than one) F statistic as reported on Table \ref{summary}. The full set includes all the available controls with the exception of a few variables. To avoid multicollinearity issues, the full set does not include: the anticipated hours of work in each day (`hours12-78`) that are replaced by the sum (`hours`); and the number of top five placements that was highly correlated with the number of wins. Other minor issues. Since our data has only a few winners with many wins, instead of using the mean number of wins of the room, we took an indicator for whether a winner was in the room or not.

```{r entrylm, results='asis'}
```

As shown in Table \ref{ols entry}, the estimated difference in entry between tournaments and races is of `r round(coef(m$entry.lm)['treatmenttournament'],2)`. This corresponds to a difference of 1 more entrant every `r round(1/coef(m$entry.lm)['treatmenttournament'])` = 1/`r coef(m$entry.lm)['treatmenttournament']` competitors or, using the specification with a log-transformed proportion (column 4), an increase by a factor of 
`r round(exp(coef(m.log$entry.lm)['treatmenttournament']),2)` = exp(`r coef(m.log$entry.lm)['treatmenttournament']`) in entry relative to races. Without any adjustment for random differences in the baseline characteristics of the rooms, the effect on entry is significantly greater than zero with a one-sided test at 10 percent level (t=`r entry.lm.sum$coef["treatmenttournament", 3]`; one-sided p=`r entry.lm.sum$coef["treatmenttournament", 4]/2`). Statistical significance increases when the effect is computed using the "partial" and "full" set of controls, thus adjusting for random differences at the room level like skills, past experience, and other demographics. Taken together, these results show evidence supporting a positive effect of tournaments on entry relative to races. In addition, our estimates show no systematic difference in entry rates between races and tournaments with reserve (as predicted by theory); and fail to detect any statistically significant difference between large and small rooms. 

Because tournaments yielded higher entry rates relative to races, it is now useful to discuss possible drivers of entry by looking at the sorting patterns across competition styles. Our theory suggests that, all else being equal, the positive gap in entry of tournaments compared to races should be driven by low-ability competitors sorting into tournaments at higher rates. Though theory prescinds from practical definitions of ability, two main types of abilities seemd the most relevent in our context. One involves proficiency in solving algorithmic problems like having adequate problem-solving skills and a good knowledge of programming. The second pertains to having as much time availability as required to solve the given problem. Our analysis thus focused on two types of data: platform data on skills and experience; and the hours of work as anticipated by competitors at registration.

To examine the sorting patterns in our data, we first estimated the conditional probability of entry as a function of our favourite ability measures --- the skill ratings and anticipated hours of work. As shown in the upper panels of Figure \ref{sorting plot}, the linear-regression estimates of the conditional probability of entry computed for the median competitor (i.e., `r median(races$hours, na.rm=TRUE)` anticipated hours) was increasing in both our ability measures --- the skill rating (left panel) and anticipated hours (right panel) --- with large differences in probability between individuals at the top and the bottom of the covariate distribution. So, entrants were more skilled than non-entrants. To see if these sorting patterns were different across tournaments and races, we then estimated the same relationships conditional on competitors being randomly assigned to races or tournaments (i.e., interacting the covariates with treatment dummies). As shown in the lower panels of Figure \ref{sorting plot}, the linear-regression estimates with interactions overlap quite well one another. This means that the propensity to enter of an individual with a given programming skills --- measured by the skill rating --- holding constant time availability --- measured by the anticipated hours of work --- was the same across treatments, and vice versa.  So, based on these measures, our data provide no evidence of a differential in ability-based sorting between tournaments and races.

```{r sortingplots, fig.width=8, fig.height=8, include=FALSE}
```

\begin{figure}
\caption{Sorting by skills and time availability}
\label{sorting plot}
\includegraphics{Figures/sortingplots-1.pdf}
\end{figure}


Differences in means for the all other covariates (not shown) supported the same conclusion --- positive and significant differences in ability between entrants and non-entrants but no differing patterns between tournaments and races. Somewhat surprisingly, the analysis of differences in means showed an unexpected difference in ability characteristics between entrants in races and those in tournaments w/reserve. As shown in Table \ref{sorting table}, those in the races had significantly more time availability and had registered to less past competitions than those in the tournaments w/reserve. Since entry was the same in both treatments, this evidence suggests the presence of a "substitution" effect. Such as substitution effect is not predicted by our theory, as it predicts differences to be driven by higher/lower entry rates, which are not expected to arise when races and tournament w/reserve have the same target quality. And we will return on this point in the discussion of the results. 

```{r sortingtable, cache=FALSE, results='asis'}
```

Let us now summarize the evidence obtained so far. Consistent with theoretical predictions, we found evidence that competitors in tournaments had higher propensity to enter the competition relative to those randomly assigned to the other treatments. While our data show stark differences between entrants and non-entrants, we did not detect significant differences in entrants' characteristics between races and tournaments. Both conditional and unconditional differences in means between races and tournaments are insignificant. In particular, we found no evidence of skill-based sorting in terms of two well-suited measures of ability ---  skill ratings and anticipated hours of work. By contrast, we found significant differences in entrants' characteristics between races and tournaments with reserve. Since entry rates are not different between these two treatment groups, a substitution effect must have occurred, which was unexpected as not predicted by theory.

## Scores

After the analysis on entry, we focused on comparing treatment effects on performance. Our model predicts that, all else being equal, tournaments with reserve will yield higher performance levels compared to races and "regular" tournaments. The model also predicts lower volatility in performance of races relative to tournaments. To investigate these issues, we collected data on scores for each solution submitted during the contest. We then focused the analysis on the highest score attained by a competitor's last submission in each room, and we divided all room values by the target quality to express the percentage relative to the target quality.[^scores]

<!-- 
The results on entry suggest that tournaments had a positive impact on competitors' participation relative to races and tournaments with reserve. The analysis of sorting showed further that the excess of entry was not driven by differences in ability --- at least according to our measures, --- raising the question of whether incentives alone --- without sorting in skills --- can generate relatively higher performance levels. 
 -->

[^scores]: During each contest, the platform keeps "provisional" and "system" scores for each solution submitted. In data science problems, provisional and system scores are computed in the same way but on different datasets to prevent the so-called "overfitting" problem (i.e., a form of model misspecification). Provisional scores are computed on a "testing" dataset and then published on the leaderboard. System scores are computed on a smaller "system testing" dataset and kept secret until the end of the contest. As these dataset are representative of the same data generating process, both scores are basically measuring the same kind of performance and indeed are highly correlated (the correlation coefficient was `r with(scores, cor(provisional, final,use='complete.obs'))` in our data). To simplify exposition, we report the analysis based on the system scores but results are the same with provisional scores as well. 


```{r scoresplot, fig.width=8, fig.height=4, include=FALSE}
```

\begin{figure}
\caption{Highest room scores by competition style and room size}
\label{scores plot}
\includegraphics{Figures/scoresplot-1.pdf}
\end{figure}

```{r scorestable, results='asis'}
```

As shown in Figure \ref{scores plot}, the distribution of the top final scores was centered around the target quality in each treatment, with higher variance in tournaments and tournaments w/reserve compared to races. The top final scores were thus below the target quality in about half of the rooms in each treatment; with larger differences between high and low scores in tournaments relative to races. 


```{r}
vt <- var.test(final.cens ~ treatment=='race', data=final)
```

Regression estimates of the treatment effects are shown in Table \ref{scores table}. In all our specifications --- with or without adjustment for random differences in the baseline characteristics of the rooms --- estimates of treatment effects were small ($<1$ percentage point) and insignificant, suggesting performance differences were too small to be detected. By contrast, using an F-test to compare the variances of two samples, we found the difference in variance between races and the other two treatments combined was significant (p=`r vt$p.value`).


Taken together, these results show that top final scores were below the target quality in about half of the rooms in each treatment. The total payout in tournaments was hence about twice as high as in the races and tournaments w/reserve, where prizes are distributed only when top solutions achieve a score equal or higher than the target. And, at the same time, the mean top scores in tournaments was significantly different from those in the other treatments. This seems to suggest that races and tournaments w/reserve were more "efficient" than tournaments. 


<!-- 
percentage of entrants in tournaments compared to both races and tournaments with reserve. It also shows that the difference in entry between tournaments and races, though it is consistently positive across room sizes, seemed more marked in small rooms compared to large rooms, suggesting sobering effects associated with size.
 -->


^[FOOTNOTE --- While final scores give a very powerful indication of performance, one problem with measuring individual performance using final scores is that any failure in the submitted code might return very low values, as shown in Figure \ref{scores over time}, that are not wholly indicative of performance. As outliers will in general bias the room means, we explored two corrective methods (1) we trimmed last scores before computing the room means; and (2) we replaced all final scores that were below the baseline score with the baseline. The first method gives a winsorized mean, which is an unbiased estimate of the average. The second approach equals censoring by  assuming that all entrants had a performance at least equal to the final score that one would obtain by submitting the BANNER's algorithm without making any useful change.]



## Speed

We now turn to examine differences in the timing of submissions. Our theory predicts that, all else being equal, solutions will be developed faster in races compared to tournaments. The prediction can be seen either with respect to the average "time" to develop a submission or the speed to develop a submission of a given quality. To test this prediction we examined he mean time of the first submission scaled by the score. 

As shown in Figure \ref{room time}, races yielded solutions, in median, about 2 days faster than tournaments; and this difference seems larger in small rooms where contestant in tournaments might have less incentives to act in advance to prevent others from entering the contest. 

To test to see if the difference between races and tournaments was greater than zero, we used a multiple regression approach. Estimates and standard errors are shown in Table \ref{ols speed}. Speed was significantly lower in races than in the other treatments. When we add controls for random differences in baseline characteristics like average experience of room competitors, the result becomes slightly insignificant, though it remains well below the significant threshold for a one-sided test. Statistical significance is higher in the specification with the log-transformed variable, which is to be preferred as it gives a better fit in terms of $R^2$. 


```{r firstsubbox, fig.width=9, fig.height=4, include=FALSE}
par(mfrow=c(1, 3))
form <- formula(days ~ treatment); ylim=c(0,8)
boxplot.custom(form, data=speed, main="All rooms", ylim=ylim)
boxplot.custom(form, data=subset(speed, room_size=='Small'), main="Small rooms\n(10 competitors)", ylim=ylim)
boxplot.custom(form, data=subset(speed, room_size=='Large'), main="Large rooms\n(15 competitors)", ylim=ylim)
```

\begin{figure}
\caption{Time of first submission by competition and room size}
\label{room time}
\includegraphics{Figures/firstsubbox-1.pdf}
\end{figure}


```{r}
speed0 <- speed
speed1 <- aggregate(provisional_first ~ room_id + treatment + room_size, data=races, mean)
speed <- merge(speed0, speed1)
speed$speed <- ((speed$provisional_first/1e6)/target) / speed$day
```


```{r speedbox, fig.width=9, fig.height=4, include=FALSE}
par(mfrow=c(1, 3))
form <- formula(((provisional_first/1e6)/target) ~ treatment); ylim=c(.5,1.1)
boxplot.custom(form, data=speed, main="All rooms", ylim=ylim)
boxplot.custom(form, data=subset(speed, room_size=='Small'), main="Small rooms\n(10 competitors)", ylim=ylim)
boxplot.custom(form, data=subset(speed, room_size=='Large'), main="Large rooms\n(15 competitors)", ylim=ylim)
```

<!-- 
\begin{figure}
\caption{Average Speed by competition and room size}
\label{room speed}
\includegraphics{Figures/speedbox-1.pdf}
\end{figure}
 -->


```{r speedlm, results='asis'}
speed$days <- NULL
speed$provisional_first <- NULL
m <- rep()
m$speed.lm <- lm(speed ~ treatment + room_size, data=speed)
m$speed.lm.partial <- update(m$speed.lm, ~ . + nwins + ntop10 + timezone + postgrad + male)
m$speed.lm.full <- lm(speed ~ . -hours12-hours34-hours56-hours78, data=speed[,-1])
m.log <- lapply(m, function(x) update(x, "log(speed) ~ .")) 

regtab(c(m, m.log), digits=2, notes.width=1, keep.stat=c('n','rsq')
	, omit="nwins|hours|rating|nreg|nsub|ntop|risk|male|time|postgrad|below|paid|year"
	, add.lines=list(c("Room controls", rep(c("no controls", "partial", "full"), 2)))
	, dep.var.labels=c("Speed","log(Speed)")
	, covariate.labels=c("Tournament","Tournament w/reserve", "Room size (small)")
	, notes="The table reports regression estimates of the effects of different competition and room size on the highest score in a room computed using three sets of room controls: ``no controls\", ``partial\", ``fulla.\" Standard errors are reported in parenthesis. ***,**, * indicate statistical significance at 1, 5, and 10 percent level."
	, caption="Estimates of the Effect of Competition Style on Production Speed"
	, label='ols speed')
```


To summarize the results obtained so far, we have found evidence supporting a higher participation in the Tournament. This higher participation, however, does not seem to be driven by low-skilled competitors. We have also found that competitors in the race made submissions faster without sacrificing performance, which suggests that they have paid higher costs from effort associated with the accelerated speed compared to other competitors. Finally, we reject the hypothesis that the Tournament with Reserve yields higher performance levels.

## Structural estimation

[TBA]
