# Entry

Differences in room entrants between different competition styles and between large and small rooms. 

```{r}
counts <- aggregate(submit ~ room + room_size + treatment, data=races, sum)

par(mfrow=c(1, 2))
boxplot(submit ~ treatment, data=counts, ylab='Entrants'); title("Competition")
boxplot(submit ~ room_size, data=counts, ylab='Entrants'); title("Room size")
```

Testing differences between threshold (race & reserve) and tournament. Bootstrap

```{r}
# Competition tournament
wilcox.test(submit ~ treatment=="tournament"
	, data=counts, alternative='less', exact=FALSE, correct=FALSE) # p=0.08

# Bootstrap 
# ... 

# Room size
wilcox.test(submit ~ room_size, data=counts, exact=FALSE, correct=FALSE) # p=0.01


```

When we turn to the individual propensity to submit, we strongly reject differences in the propensity to submit between large and small rooms. No evidence of competition styles effects.

```{r}
# Submit and room size
tab.size <- with(races, table(submit, room_size))
fisher.test(tab.size)  # p = 0.98

# Submit and competition styles
tab <- with(races, table(submit, treatment))
fisher.test(tab)  # p = 0.52

# Competition styles with target
tab <- with(races, table(submit, treatment=='tournament'))
fisher.test(tab, alternative='greater') # p=0.15
```

If we assume uniform priors, we can easily compute the posteriors in each treatment. 
(Not sure what we can do with this result.)

```{r}
# Bayesian analysis
# Compute posteriors Beta(1 + success, 1 + n - success)
plot.posterior <- function(x, ...) {
	tab <- with(races, table(submit, treatment))
	param <- data.frame(tab + 1)
	index <- param$treatment==x
	shape <- param[index, ]
	curve(dbeta(x, shape$Freq[2], shape$Freq[1]), ...)
}

# PLOTs
plot.posterior('race', from=0.1, to=0.5, xlab="propensity to submit", ylab='posterior density')
plot.posterior('tournament', add=TRUE, lty=2)
plot.posterior('reserve', add=TRUE, lty=3)
title("Beta(y + alpha, n-y + beta)")
legend("topright", legend=levels(races$treatment), lty=1:3, bty='n')
```


# Regression analysis of entry

Impute missing values at random for the survey.  Ignore missing ratings (or impute them). 

```{r}
within(dat, {
	set.seed(25978)
	rating.100 <- rating / 100
	rated <- !is.na(rating)
	rating.100imp <- impute(rating/100, "zero")
	hours.imp <- impute(hours, "random")
	risk.imp <- impute(risk, "random")
	grad.imp <- impute(grad, "random")
	male.imp <- impute(male, "random")
	below30.imp <- impute(below30, "random")
	timezone.imp <- impute(timezone, "random")
	expert <- cut(submissions, quantile(submissions[!is.na(rating)]), include=TRUE)
}) -> dat.imp
```

Fitting the model

```{r}

# First model has no covariates (i.e., $\gamma=0$)
summary(m0 <- glm(submit ~ treatment, binomial(logit), data=dat.imp))

# The second model adds the main skill rating measure which is available for 2/3 of our population. It seemed better to rescale rating in 100-point units and center it on the median value. Thus, the estimate of the intercept can be easily transformed in the probability of participation of the median rated individual assigned to a room with a race competition style.

summary(m1 <- update(m0, " ~ . + rating.100"))
summary(m1bis <- update(m0, " ~ . + rating.100imp + rated"))

# The third column adds time availability (hours)
summary(m2 <- update(m1bis, " ~ . + hours.imp"))

# ... add demographics to m2
summary(m3 <- update(m2, " ~ . + timezone.imp + grad.imp + below30.imp + male.imp"))

# ... add risk aversion
summary(m4 <- update(m2, " ~ . + risk.imp"))

# ... add everything stepwise regression
summary(m5 <- step(update(m3, " ~ . + risk.imp")))

# Compare models 
models <- list(m0, m1, m1bis, m2, m3, m4, m5)
stargazer(models, type='text', digits=2)
```

Explore accuracy of predictions of the stepwise model

```{r}
# Compare models in terms of prediction accuracy
accuracy <- function(fit) {
	yhat <- predict(fit, type='response')
	tab <- table(predicted=ifelse(yhat>0.5, 1, 0), actual=fit$y)
	tp <- tab[2,2]
	fp <- tab[2,1]
	fn <- tab[1,2]
	precision <- tp / (tp+fp)
	recall <- tp / (tp + fn)
	fmeasure <-  2 * precision * recall / (precision + recall)
	list(conf.table=tab, precision=precision, recall=recall, f.measure=fmeasure)
}
accuracy(m5)

summarize.fit <- function(x) {
	yhat <- predict(x)
	with(x, plot(jitter(y) ~ yhat, col=ifelse(yhat>0,'brown', 'blue'), pch=16, xlab="ability ~ Logistic"))
	curve(ilogit, add=T)
}
par(mfrow=c(3, 3))
sapply(models, summarize.fit)
```

Study interaction effecs first with models on a subset and then using interaction terms in the regression. 

```{r}
# Using Akaike criterion to select the best model, we now compute the model for each treatment alone
summary(race <- update(m5, "~ . -treatment", subset=treatment=='race'))
summary(tour <- update(m5, "~ . -treatment", subset=treatment=='tournament'))
summary(rese <- update(m5, "~ . -treatment", subset=treatment=='reserve'))

# Interact on stepwise model
summary(interact <- update(m5, "~ (.)*treatment"))
summary(stepwise <- step(interact))

# Interaction on full model
summary(interact.full <- update(m4, "~ (.)*treatment"))
summary(stepwise.full <- step(interact.full))

models <- list(m5, race, tour, rese, interact, stepwise, interact.full, stepwise.full)
stargazer(models, type='text', digits=3)

par(mfrow=c(3, 3))
sapply(models, summarize.fit)
```


```{r}
# This identification result holds under the assumption that the skill distribution is logistic. Next, we relax this distributional assumption. First, we check different distributions [e.g., probit, cauchit, cloglog]. We find Probit model seems slightly better in terms of deviance
probit <- update(m5, family=binomial(probit))
cauchit <- update(m5, family=binomial(cauchit))
cloglog <- update(m5, family=binomial(cloglog))
fit <- list(logit=m5, probit=probit, cauchit=cauchit, cloglog=cloglog)
cbind(deviance=sapply(fit, deviance), n=sapply(fit, function(x) length(x$y)))

#  ... but not necessarily in terms of prediction accuracy
accuracy(probit)
accuracy(m5)
```

We try generalized additive models

```{r}
# GAMs Generalized additive models
m.gam <- mgcv::gam(submit ~ treatment + s(hours.imp) + s(rating.100imp), data=dat.imp, family=binomial)
summary(m.gam)
plot(m.gam)
```

And non-parametric models like KS and Ichimura.

```{r}
require(np)

# Ichimura
m.np <- npindexbw(as.numeric(submit) ~ rating.100imp + hours.imp + treatment, data=dat.imp)
summary(m.np)
plot(m.np)

# Klein-spady ... Not sure about this implementation!
kleinspad <- npindexbw(as.numeric(submit) ~ rating.100imp + hours.imp + treatment, data=dat.imp, method="kleinspady")
summary(kleinspad)

plot(kleinspad)
# Bayesian models
#model 	<- "submit ~ treatment + tothours.imp + mm_rating.100 + educ+gender+timezone"
# bayes <- arm::bayesglm(model, family=binomial)
# summary(bayes)
```

